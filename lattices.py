import numpy as np
from numpy.linalg import inv
import math
from copy import deepcopy
from random import randint
from numpy.linalg import norm


'''
A unimodular row operation on a matrix is one of the following elementary row operations:
* multiply any row by -1,
* interchange any two rows,
* add an integral multiple of any row to any other row.
If we apply unimodular row operations to the matrix X whose rows contain a basis of a
lattice L, then we obtain another basis ot the same lattice.

Input:
------
* A 2d ndarray that represents a matrix X whose rows x1,x2,..,xn of R^n contain a basis of
   a lattice L.
* An operation count k: the number of unimodular row operations to be applied to the matrix X.
* A range parameter r to limit the scalars.

Output:
------
* A 2d ndarray whose row vectors are another basis of the same lattice L.
'''
def unimodular_row_operations(X,k,r):

    # m is the number of rows and n the number of columns.
    m,n = X.shape

    # Apply k unimodular row operations
    for i in range(k):
        # There are 3 kind of possible unimodular row operations,
        # so choose randomly which one to be applied next.
        c = randint(1,3)

        # The 1st option is to multiply any row by -1:
        if (c==1):

            # choose the row randomly
            row = randint(0,m-1)

            X[row] = deepcopy(X[row] * (-1))

        # The 2nd option is to interchange any two rows:
        elif (c==2):
            # Choose two rows randomly:
            row1 = randint(0,m-1)
            row2 = randint(0,m-1)

            # Interchange the rows:
            tmp = deepcopy(X[row1])
            X[row1] = deepcopy(X[row2])
            X[row2] = deepcopy(tmp)

        # The 3rd option is to add an integral multiple of any row to any other row.
        else:
            # Choose two rows randomly:
            row1 = randint(0,m-1)
            row2 = randint(0,m-1)
            # they have to be different:
            if (row1 == row2):
                while (row1==row2):
                    row2 = randint(0,m-1)

            # Chosse the integral multiple randomly:
            s = randint(1,r)

            X[row1] = deepcopy(X[row1]) + s*deepcopy(X[row2])

    return X




'''
The Gram matrix delta(L) of the lattice L is the mxn matrix in which the (i,j) entry
is the scalar product of the i-th and j-th basis vectors.

Input:
------
* A 2d ndarray that represents an matrix X whose rows x1,x2,..,xm are linearly independent vectors in R^m (m<=n)
  that spann an m-dimensional lattice L

Output:
-------
* A 2d ndarray that is the mxm Gram matrix of the lattice L.
'''
def gram_matrix(X):
    Xt = X.transpose()
    G = X.dot(Xt)
    return G




'''
The determinant of a lattice L is defined as the square root of its Gram matrix.
Note that the determinant of a lattice does not depend on the choice of basis.
There is a geometric interpretation: The determinant is the m-dimensional volume of
the parallelipiped in R^n whose edges are the lattice basis vectors.

Input:
------
* A 2d ndarray that represents an matrix X whose rows x1,x2,..,xm are linearly independent vectors in R^m (m<=n)
  that spann an m-dimensional lattice L

Output:
------
* The determinant of the Lattice L.
'''
def lattice_determinant(X):
    G = gram_matrix(X)
    detG = np.linalg.det(G)
    result = math.sqrt(detG)
    return result




'''
Perform the classical Gram-Schmidt algorithm for converting an arbitrary basis of
R^n into an orthogonal basis. We do not normalize the vectors here.

Input:
------
* A 2d ndarray that represents an nxn matrix in which row(!) i is the vector xi.
  The rows x1,x2,...xn build a basis in R^n.

Output:
------
* A 2d ndarray that represents an nxn matrix Y in which row i is the vector yi.
  The rows y1,y2,...,yn build an orthogonal basis in R^n.
* A 2d ndarray that represents the Gram-matrix M (the matrix of GSO coefficients) with X = MY.

Note: The Gram-Schmidt basis vectors y1, y2, ... ,yn are usually not in the lattice generated by x1,...,xn.
In general y1,...,yn are not integral linear combinations of x1,...,xn.
'''
def gram_schmidt(X):
    n, m = X.shape

    X = X.astype(float)

    M = np.zeros((n, m))
    Y = deepcopy(X)

    for i in range(n):
        for j in range(i):
            M[i][j] = X[i].dot(Y[j]) / Y[j].dot(Y[j])
            Y[i] = Y[i] - M[i][j] * Y[j]

    for i in range(n):
        M[i][i] = 1

    return Y,M




'''
This algorithm is called the LLL algorithm after the initials of its authors,
A. K. Lenstra, H. W. Lenstra Jr. und L. Lovasz.
It is a polynomial time lattice reduction algorithm. Suppose we are given a "bad" basis x1,x2,...xn = X of
a lattice L. Using the LLL algorithm we can find a "good" basis x1', x2',...,xn' = X'. Each vector xi' is
"almost orthogonal" to the span of the previous vectors.
Suppose (x_1',x_2',...x_n') is a basis of R^n and (x_1*,x_2*,...x_n*) its Gram-Schmidt orthogonal basis. The basis
(x_1',x_2',...x_n') is called reduced, if
    ||x_i*||^2 <= 2 ||x_i+1||^2 for 1 <= i < n.
The reduction parameter a (alpha) has here the standard value of 3/4, and therefore the auxiliary parameter
b (beta) = 4/(4a-1) is 2.

Input:
------
* A 2d ndarray that represents a matrix X whose rows x1,x2,..,xm are linearly independent vectors in R^n (m<=n)
  that spann an m-dimensional lattice L

Output:
-------
* A 2d ndarray that repersents a matrix X' whose rows x1',x2',...,xm' are a reduced basis of the basis X.
'''
def lll(X):

    m, n = X.shape

    if m > n:
        raise ValueError('The number of basis vectors excees the space dimensionality')

    X = X.astype(float)

    Y,M = gram_schmidt(X)

    alpha = 0.5

    i = 1
    while(i<m):

        for j in range(i-1,-1,-1):

            X[i] = deepcopy(X[i]) - int(round(deepcopy(M[i,j]))) * deepcopy(X[j])

            if abs(M[i,j] > 0.5):
                # update the GSO:
                Y,M = gram_schmidt(X)

        # For standard value a = 3/4 resp. b = 2:
        if (i>0) and (norm(Y[i-1])**2 > 2 * norm(Y[i])**2):
            # Interchange X[i] and X[i-1]:
            tmp = deepcopy(X[i])
            X[i] = deepcopy(X[i-1])
            X[i-1] = deepcopy(tmp)

            # Update the GSO:
            Y,M = gram_schmidt(X)

            i = i-1

        else:
            i = i+1

    return X




'''
Perform a Cholesky decomposition of a symmetric positive definite mxm matrix G.
Output is a diagonal mxm matrix D and an upper triangular matrix U with ones on
the diagonal such that G = U^tDU.
This is a slightly modified version of the classical Cholesky decomposition R^tR.
'''
def cholesky_DU(G):
    U = G.astype(float)
    m = len(U)

    for j in range(m - 1):
        for i in range(j + 1, m):
            # Add -Uij/Ujj times row j of U to row i:
            q = - U[i, j] / U[j, j]
            for k in range(m):
                U[i, k] = U[i, k] + q * U[j, k]

    # D is a diagonal matrix with positive entries d1,...dm on the diagonal:
    D = np.zeros((m, m))
    for i in range(m):
        D[i, i] = U[i, i]

    # Make sure that U has ones on the diagonal:
    for i in range(m):
        for j in range(m):
            U[i, j] = U[i, j] / D[i, i]

    return D, U




'''
The Fincke-Pohst Algorithm is an algorithm for finding not merely one short vector
in a lattice, but for enumerating all vectors in a lattice with length less than
a given upper bound C. In particular, this allows us to determine a shortest nonzero
lattice vector.

Input:
------
* A 2d ndarray that represents a matrix Bt whose rows x1,x2,..,xm are linearly independent vectors in R^n (m<=n)
  that spann an m-dimensional lattice L

* An upper Bound C for the euclidian square length of the lattice vectors.

Output:
-------
* The lattice vectors with square length at most C.
'''
def fincke_pohst(Bt, C):

    m,n = Bt.shape

    if m>n:
        raise ValueError('The number of basis vectors excees the space dimensionality')

    Bt = Bt.astype(float)

    B = Bt.transpose()

    # Calculate the Gram matrix for the basis.
    # Note that G is a symmetric positive definite matrix.
    G = Bt.dot(B)

    # Get the matrices D and U of the Choleksy decomposition G = U^tDU.
    D, U = cholesky_DU(G)
    # D is a diagonal matrix with positive entries d1...dm on the diagonal,
    # U is an upper triangular matrix with ones on the diagonal.

    # G has size mxm.
    m = len(G)

    results = []
    zero_vector = np.zeros((m))
    results.append(zero_vector)

    # Any vector in the lattice is an integral linear combination of the basis
    # vectors b1,b2,...,bm (which are tge column of the nxm matrix B) with a
    # coefficient vector x = [x1,x2,...,xm].

    # We obtain the range of possible values for xk as k decreases from m down to 1,
    # respectively in the array notation form m-1 down to 0:
    for k in range(m-1,-1,-1):

        new_results = []

        for r in results:
            x = r

            # Sk = sum_{i=k+1}^{m} ( D[i,i] * (x[i] + sum_{j=i+1}^{m] ( U[i,j] * x[j] ) )^2 )
            Sk = sum(D[i,i] * (x[i] + sum(U[i,j]*x[j] for j in range(i+1,m)) )**2 for i in range(k+1,m))

            # Tk = sum_{j=k+1}^{m} ( U[k,j] * x[j] )
            Tk = sum(U[k,j]*x[j] for j in range(k+1,m))

            lower_bound = math.ceil(- math.sqrt((C-Sk)/D[k,k])-Tk)
            upper_bound = math.floor(math.sqrt((C-Sk)/D[k,k])-Tk)

            # The possible values for xk are the integers in the range lowerBound to upperBound.
            # The list of partial results from the previous step is extended by including each
            # possible value of the new coefficient.
            for xk in range(int(lower_bound), int(upper_bound)+1, 1):
                x[k] = xk
                new_results.append(deepcopy(x))

        results = new_results

    vector_list = []
    for x in results:
        np.asarray(x)

        # v = Bx gives the short lattice vectors for each coefficient vector x.
        v = B.dot(x)
        v = v.astype(int)
        vector_list.append(v)

    # To make the results more suitable, let's sort them by euclidian norm.
    vector_list.sort(key=norm)

    return vector_list




'''
Combined with the LLL algorithm, the FP algorithm becomes a more efficient hybrid.
This involves two insights:
* We can use the LLL algorithm to modify the quadratic form obtained for from the Gram matrix
  of the lattice basis; this will diminish the ranges for the components of the partial coordinate vectors.
* We can reorder the vectors in the computation of the rational Cholesky decomposition of the Gram matrix;
  this will increase the chance that a partial coordinate vector cannot be extended.
'''
def fincke_pohst_with_lll(Bt,C):

    m, n = Bt.shape

    if m > n:
        raise ValueError('The number of basis vectors excees the space dimensionality')

    Bt = Bt.astype(float)

    B = Bt.transpose()

    # Compute the Gram matrix.
    G = Bt.dot(B)

    # Make the classical Cholesky decomposition G = R^t R = L L^t
    L = np.linalg.cholesky(G)
    R = L.transpose()

    # We consider the inverse matrix R^(-1) and the m-dimensional lattice in R^m with basis
    # consisting of the rows of R^(-1).
    Rinv = inv(R)
    # We apply the LLL algorithm to this basis, and obtain a reduced basis which we regard as the rows of
    # the matrix S^(-1):
    Sinv = lll(Rinv)

    # The change basis matrix from the rows of R^(-1) to the rows of S^(-1) will be denoted by X^(-1),
    # so we have the formula X = (S^(-1) R)^(-1).
    X = inv(Sinv.dot(R))

    S = inv(Sinv)

    # We make a permutation matrix P^(-1) for which the matrix P^(-1)S^(-1) = (SP)^(-1) has rows of decreasing
    # Euclidian norm.
    permutation = np.argsort(norm(Sinv,axis=0))
    m = len(permutation)
    Pinv = np.zeros((m,m))
    for i in range(m):
        Pinv[i,permutation[i]] = 1

    P = inv(Pinv)

    # We apply the same permutation to the columns of S, and obtain the matrix SP.
    SP = S.dot(P)
    SPt = SP.transpose()

    # We now compute the new Gram matrix H, which is the symmetric positive definite matrix defined by the
    # equation H = (SP)^t (SP).
    H = SPt.dot(SP)

    # We apply the rational cholesky decomposition on H:
    E,V = cholesky_DU(H)


    # Now we apply the original Fincke-Pohst algorithm to the quadratic form corresponding to the new
    # Gram matrix H:

    results = []
    zero_vector = np.zeros((m))
    results.append(zero_vector)

    for k in range(m - 1, -1, -1):

        new_results = []

        for r in results:
            z = r

            # Sk = sum_{i=k+1}^{m} ( E[i,i] * (z[i] + sum_{j=i+1}^{m] ( V[i,j] * z[j] ) )^2 )
            Sk = sum(E[i, i] * (z[i] + sum(V[i, j] * z[j] for j in range(i + 1, m))) ** 2 for i in range(k + 1, m))

            # Tk = sum_{j=k+1}^{m} ( V[k,j] * z[j] )
            Tk = sum(V[k, j] * z[j] for j in range(k + 1, m))

            lower_bound = math.ceil(- math.sqrt((C - Sk) / E[k, k]) - Tk)
            upper_bound = math.floor(math.sqrt((C - Sk) / E[k, k]) - Tk)

            # The possible values for zk are the integers in the range lowerBound to upperBound.
            # The list of partial results from the previous step is extended by including each
            # possible value of the new coefficient.
            for zk in range(int(lower_bound), int(upper_bound) + 1, 1):
                z[k] = zk
                new_results.append(deepcopy(z))

        results = new_results



    vector_list = []
    for z in results:
        # z gives the coefficient vectors from the application of the FP algorithm on the reduced
        # Gram matrix H:
        np.asarray(z)

        # y gives the permuted coefficient vectors y = Px.
        y = P.dot(z)

        # x gives the coefficient vectors x = Xy before the LLL algorithm.
        x = X.dot(y)

        # w gives the short lattice vectors w = Bx.
        w = B.dot(x)

        # Make sure there are no round-off errors.
        for i in range(len(w)):
            w[i] = round(w[i])

        w = w.astype(int)
        vector_list.append(w)

    vector_list.sort(key=norm)

    return vector_list
